Scopus
EXPORT DATE: 15 November 2023

@ARTICLE{Wang2022694,
	author = {Wang, Ming and Zhang, Jie and Zhang, Peng and Cui, Li and Zhang, Guoqing},
	title = {Independent double DQN-based multi-agent reinforcement learning approach for online two-stage hybrid flow shop scheduling with batch machines},
	year = {2022},
	journal = {Journal of Manufacturing Systems},
	volume = {65},
	pages = {694 – 708},
	doi = {10.1016/j.jmsy.2022.11.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141920213&doi=10.1016%2fj.jmsy.2022.11.001&partnerID=40&md5=f7287c1765e224a706992ab4425d4de6},
	affiliations = {College of Mechanical Engineering, Donghua University, Shanghai, China; Institute of Artificial Intelligence, Donghua University, Shanghai, China; Xinfengming Group Huzhou Zhongshi Technology Co. Ltd, Zhejiang, China},
	abstract = {Two-stage hybrid flow shop scheduling with batch machines and jobs arriving over time is complex and challenging in various real-world production scenarios. For the online scheduling problem, traditional heuristic rules can quickly respond to dynamically arrived jobs, while with poor and unstable performance. To close the research gap in the problem, this paper proposes an independent double deep-q-network-based multi-agent reinforcement learning (MA-IDDQN) approach to produce an adaptive rule for batch forming and scheduling. Specifically, the online scheduling problem is transformed into a cooperative Markov decision process by defining state space, action space, and reward function for different agents. Then, two agents are constructed and trained via double DQN to address the batch forming task and scheduling task respectively. Meanwhile, multi-agent cooperates through the behavior analysis mechanism among agents. Moreover, we designed a ε-greedy policy considering waiting in batch forming to make a reasonable decision through historical data. To validate the proposed approach, 27 instances with different scales are settled and contrasted. By comparing with frequently-used heuristic rules and other deep reinforcement learning methods, the experimental results demonstrate that the MA-IDDQN can integrate online batch forming and scheduling to minimize the total tardiness time effectively. © 2022 The Society of Manufacturing Engineers},
	author_keywords = {Batch machines; Jobs arriving over time; Multi-agent reinforcement learning; Online scheduling; Two-stage hybrid flow shop},
	keywords = {Deep learning; E-learning; Heuristic methods; Job shop scheduling; Learning systems; Machine shop practice; Multi agent systems; Reinforcement learning; Scheduling algorithms; Batch jobs; Batch machines; Heuristic rules; Hybrid flow shop scheduling; Job arriving over time; Multi-agent reinforcement learning; Online scheduling; Reinforcement learning approach; Scheduling problem; Two-stage hybrid flow shop; Markov processes},
	correspondence_address = {J. Zhang; Donghua University, Institute of Artificial Intelligence, Shanghai, Room 2406, College Building No. 2, 2999 Renmin North Road, Songjiang District, 201620, China; email: mezhangjie@dhu.edu.cn},
	publisher = {Elsevier B.V.},
	issn = {02786125},
	coden = {JMSYE},
	language = {English},
	abbrev_source_title = {J Manuf Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Qin2023242,
	author = {Qin, Zhaojun and Johnson, Dazzle and Lu, Yuqian},
	title = {Dynamic production scheduling towards self-organizing mass personalization: A multi-agent dueling deep reinforcement learning approach},
	year = {2023},
	journal = {Journal of Manufacturing Systems},
	volume = {68},
	pages = {242 – 257},
	doi = {10.1016/j.jmsy.2023.03.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151720802&doi=10.1016%2fj.jmsy.2023.03.003&partnerID=40&md5=f89ce4c76412692a6bfe46518e1b94f5},
	affiliations = {Department of Mechanical and Mechatronics Engineering, The University of Auckland, New Zealand},
	abstract = {Mass personalization is rapidly approaching. In response, manufacturing systems should be capable of autonomously changing production plans, configurations and schedules under dynamic manufacturing environments for producing personalized products. Self-organizing manufacturing network is a promising paradigm for mass personalization. The backbone of a self-organizing manufacturing network is an adaptive production scheduling method to dynamically allocate and sequence manufacturing jobs under dynamic settings, such as stochastic processing time or unplanned machine breakdown. However, existing production scheduling methods (i.e., heuristic rules, meta-heuristic algorithms, and existing reinforcement learning models) fail to automatically optimize production schedules while maintaining stable manufacturing performance, under dynamic settings. In this paper, we designed a reinforcement learning-based static-training-dynamic-execution approach for dynamic job shop scheduling problems. The scheduling policies are learned from static scheduling instances by a multi-agent dueling deep reinforcement learning approach. Under this approach, we proposed new representations of observation, action, reward, and cooperation mechanisms between agents. The learned scheduling policies are then deployed to a dynamic scheduling system where stochastic processing time and unplanned machine breakdown randomly occur. Extensive simulation experiments demonstrated that our approach outperforms heuristic rules on makespan under two dynamic manufacturing settings. © 2023 The Society of Manufacturing Engineers},
	author_keywords = {Dynamic flexible job shop scheduling problem; Mass personalization; Multi-agent production scheduling; Reinforcement learning; Self-organizing manufacturing network},
	keywords = {Deep learning; Heuristic algorithms; Heuristic methods; Job shop scheduling; Multi agent systems; Production control; Stochastic systems; Dynamic flexible job shop scheduling problem; Flexible job-shop scheduling problem; Manufacturing networks; Mass personalization; Multi agent; Multi-agent production scheduling; Personalizations; Production Scheduling; Reinforcement learnings; Self-organising; Self-organizing manufacturing network; Reinforcement learning},
	correspondence_address = {Y. Lu; email: yuqian.lu@auckland.ac.nz},
	publisher = {Elsevier B.V.},
	issn = {02786125},
	coden = {JMSYE},
	language = {English},
	abbrev_source_title = {J Manuf Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Wang2023,
	author = {Wang, Teng and Hu, Xiaofeng and Zhang, Yahui},
	title = {A DRL based approach for adaptive scheduling of one-of-a-kind production},
	year = {2023},
	journal = {Computers and Operations Research},
	volume = {158},
	doi = {10.1016/j.cor.2023.106306},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162173703&doi=10.1016%2fj.cor.2023.106306&partnerID=40&md5=85224366e594be0236de4d1bb9bf1d6a},
	affiliations = {School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Shanghai Key Laboratory of Advanced Manufacturing Environment, Shanghai, 200240, China; 5G Intelligent Manufacturing Research Center, Institute of Marine Equipment, Shanghai Jiao Tong University, Shanghai, 200240, China},
	abstract = {Adaptive scheduling is an efficient strategy for one-of-a-kind production (OKP) widespread in heavy industries to address its challenges of the high degree of customization and frequent interference. However, the scheduling procedure meets the problems of complex constraints and short decision time. To address these issues, this study aims to develop a reinforcement learning-based algorithm to solve the adaptive scheduling problem of OKP. The objective is to minimize the makespan. Firstly, the OKP adaptive scheduling problem is modeled as a Markov decision process, and a reinforcement learning algorithm is used to train the scheduling agent offline. Then, the trained agent can make scheduling decisions adaptively according to the production state in a short time. To evaluate the effectiveness of the proposed algorithm, a large number of numerical experiments are performed on the benchmark datasets and a practical engineering case. The results show that the proposed algorithm is competitive in static testing. And it can also achieve the balance between scheduling performance and computation time during adaptive scheduling. © 2023 Elsevier Ltd},
	author_keywords = {Adaptive scheduling; Deep reinforcement learning; One-of-a-kind production; Priority rule},
	keywords = {Deep learning; Large dataset; Learning algorithms; Markov processes; Adaptive scheduling; Complex constraints; Customisation; Deep reinforcement learning; Efficient strategy; Heavy industries; One-of-a-kind production; Priority rules; Reinforcement learnings; Scheduling problem; Reinforcement learning},
	correspondence_address = {X. Hu; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; email: wshxf@sjtu.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {03050548},
	coden = {CMORA},
	language = {English},
	abbrev_source_title = {Comp. Oper. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mzili202390,
	author = {Mzili, Toufik and Mzili, Ilyass and Riffi, Mohammed Essaid and Pamucar, Dragan and Kurdi, Mohamed and Ali, Ali Hasan},
	title = {Optimizing production scheduling with the spotted hyena algorithm: A novel approach to the flow shop problem},
	year = {2023},
	journal = {Reports in Mechanical Engineering},
	volume = {4},
	number = {1},
	pages = {90 – 103},
	doi = {10.31181/rme040116072023m},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168716413&doi=10.31181%2frme040116072023m&partnerID=40&md5=4950d14992bcf49ce6bef33888b8be3f},
	affiliations = {Department of Computer Science, Laboratory LAROSERI, Faculty of Science, Chouaib Doukkali University, EI Jadida, Morocco; Laboratory of research in management and Development, Department of Management, Faculty of Economics Hasan 1st University, Settat, Morocco; Department of Operations Research and Statistics, Faculty of Organizational Sciences, University of Belgrade, Belgrade, Serbia; Faculty of Informatics Engineering, Idlib University, Idlib, Syrian Arab Republic; College of Engineering Technology, National University of Science and Technology, Dhi Qar, 64001, Iraq; Institute of Mathematics, University of Debrecen, Hungary},
	abstract = {The spotted hyena optimization algorithm (SHOA) is a novel approach for solving the flow shop-scheduling problem in manufacturing and production settings. The motivation behind SHOA is to simulate the social dynamics and problem-solving behaviors of spotted hyena packs in order to identify and implement optimal schedules for jobs in a flow shop environment. This approach is unique compared to other optimization algorithms such as WOA, GWO, and BA. Through extensive experimentation, SHOA has been shown to outperform traditional algorithms in terms of solution quality and convergence speed. The purpose of this study is to present the details of the SHOA algorithm, demonstrate its effectiveness, and compare its performance with other optimization approaches. The method used in this study includes extensive experimentation and comparison with other algorithms. The findings of this study show that SHOA is a promising tool for optimizing production processes and increasing efficiency. The implications of this study are that SHOA can be used as an effective tool for solving flow shop-scheduling problems in manufacturing and production settings. 2023 Regional Association for Security and crisis management and European centre for operational research. All rights reserved.},
	author_keywords = {Artificial intelligence; Flow shop problem; Flow shop scheduling; Job sequencing; Optimization algorithm; Production flow; Production scheduling; Resource allocation; Spotted hyena; Swarm intelligence},
	correspondence_address = {T. Mzili; Department of Computer Science, Laboratory LAROSERI, Faculty of Science, Chouaib Doukkali University, EI Jadida, Morocco; email: mzili.t@ucd.ac.ma},
	publisher = {Regional Association for Security and crisis management},
	issn = {26835894},
	language = {English},
	abbrev_source_title = {Rep. Mech. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Takeda-Berger2023,
	author = {Takeda-Berger, Satie L. and Frazzon, Enzo M.},
	title = {An inventory data-driven model for predictive-reactive production scheduling},
	year = {2023},
	journal = {International Journal of Production Research},
	doi = {10.1080/00207543.2023.2217297},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161375690&doi=10.1080%2f00207543.2023.2217297&partnerID=40&md5=0986ec76f469b248d492f33466a9f232},
	affiliations = {Department of Production Engineering and Systems, Federal University of Santa Catarina, Florianópolis, Brazil},
	abstract = {Scheduling is a complex task due to the need to optimise multiple competing objectives and react to unpredictable events that may occur during production execution. The strategy of predictive-reactive scheduling can be used to reconcile the conflict between the original schedule and the current shop floor situation. This study seeks to present an inventory data-driven predictive-reactive production scheduling model that supports the evolving concepts of the Industry 4.0. Periodically, a machine learning technique provides predictive scheduling considering a best-case scenario according to an established Key Performance Indicator (KPI). Then, material non-availability causes disruptions in production, which triggers the Simulation-Based Optimization (SBO) method to handle these events. Thus, SBO provides a reactive schedule with the best set of priority rules to sequence jobs on each machine according to the data on the shop floor. This model was validated with a real case study using data collected from a metal-mechanical company. Considering the service level KPI, the results showed that the model is able to find a better solution in the compared scenarios. Therefore, even in a dynamic and stochastic scenario, with machine breakdowns, quality problems, raw material delays, and accuracy issues, the model proved efficient in mitigating these variations’ effects. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {data-driven; inventory; machine learning; predictive-reactive; Production scheduling; simulation-based optimisation},
	keywords = {Benchmarking; Floors; Optimization; Production control; Stochastic models; Stochastic systems; Data driven; Data-driven model; Inventory; Inventory data; Key performance indicators; Machine-learning; Predictive-reactive; Production Scheduling; Shopfloors; Simulation-based optimizations; Machine learning},
	correspondence_address = {S.L. Takeda-Berger; Department of Production Engineering and Systems, Federal University of Santa Catarina, Florianópolis, Carvoeira, Santa Catarina, 88040-535, Brazil; email: satietakeda@hotmail.com},
	publisher = {Taylor and Francis Ltd.},
	issn = {00207543},
	coden = {IJPRB},
	language = {English},
	abbrev_source_title = {Int J Prod Res},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dupuis2023,
	author = {Dupuis, Ambre and Dadouchi, Camélia and Agard, Bruno},
	title = {A decision support system for sequencing production in the manufacturing industry},
	year = {2023},
	journal = {Computers and Industrial Engineering},
	volume = {185},
	doi = {10.1016/j.cie.2023.109686},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174719527&doi=10.1016%2fj.cie.2023.109686&partnerID=40&md5=caa7d23eb60d6c6f098118a905b3de52},
	affiliations = {Laboratoire en Intelligence des Données (LID), Canada; Centre Interuniversitaire de Recherche sur les Réseaux d'Entreprise, la Logistique et le Transport (CIRRELT), Canada; Département de mathématiques et génie industriel, Polytechnique Montréal, succursale Centre-Ville, Montréal, Québec, CP 6079, Canada},
	abstract = {In the context of labour shortages and an aging population, it is important to support knowledge transfer from experienced workers. Sometimes, this can be done through optimization models, but it is not always possible to get and/or have explicit rules and constraints that could impact a decision when making complex decisions, such as in job sequencing. In such situations, a gap can occur between what the decision models suggest and what experienced planners will actually do. This is because workers may take into account a range of information and knowledge that has been gained from previous decisions that cannot be included in the decision models. The objective of this paper is to address this point by providing a decision support tool based on learning, without producing an optimization model, that is capable of replicating the production sequencing decisions of an experienced planner in a dynamic and complex production context. A methodology is proposed based on a Seq2Seq-LSTM model using the Teacher Forcing method with the Beam Search algorithm. Results are refined by a statistical and constrained method. The N scenarios with the best global scores are proposed as production sequencing recommendations. Promising results obtained in an industrial case study are presented. The best-performing learning model using production and demand data achieves a prediction rate of 52.43% for the prediction of a sequence of three products when one option is considered, and almost 70% when 10 options are considered. © 2023 Elsevier Ltd},
	author_keywords = {Deep learning; Knowledge transfer; LSTM; Production sequencing; Recurrent neural network; Seq-to-seq},
	keywords = {Complex networks; Knowledge management; Learning systems; Long short-term memory; Optimization; Decision modeling; Deep learning; Knowledge transfer; Labor shortages; LSTM; Manufacturing industries; Optimization models; Production sequencing; Seq-to-seq; Workers'; Decision support systems},
	correspondence_address = {A. Dupuis; Laboratoire en Intelligence des Données (LID), Canada; email: ambre-manon.dupuis@polymtl.ca},
	publisher = {Elsevier Ltd},
	issn = {03608352},
	coden = {CINDD},
	language = {English},
	abbrev_source_title = {Comput Ind Eng},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2022,
	author = {Chen, Shifan and Huang, Zuyi and Guo, Hongfei},
	title = {An End-to-End Deep Learning Method for Dynamic Job Shop Scheduling Problem},
	year = {2022},
	journal = {Machines},
	volume = {10},
	number = {7},
	doi = {10.3390/machines10070573},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137243891&doi=10.3390%2fmachines10070573&partnerID=40&md5=e73a9f75af6b83f01ca71af5308a4ae6},
	affiliations = {School of Intelligent Systems Science and Engineering, Jinan University, Zhuhai, 519070, China; Institute of Physical Internet, Jinan University, Zhuhai, 519070, China},
	abstract = {Job shop scheduling problem (JSSP) is essential in the production, which can significantly improve production efficiency. Dynamic events such as machine breakdown and job rework frequently occur in smart manufacturing, making the dynamic job shop scheduling problem (DJSSP) methods urgently needed. Existing rule-based and meta-heuristic methods cannot cope with dynamic events in DJSSPs of different sizes in real time. This paper proposes an end-to-end transformer-based deep learning method named spatial pyramid pooling-based transformer (SPP-Transformer), which shows strong generalizability and can be applied to different-sized DJSSPs. The feature extraction module extracts the production environment features that are further compressed into fixed-length vectors by the feature compression module. Then, the action selection module selects the simple priority rule in real time. The experimental results show that the makespan of SPP-Transformer is 11.67% smaller than the average makespan of dispatching rules, meta-heuristic methods, and RL methods, proving that SPP-Transformer realizes effective dynamic scheduling without training different models for different DJSSPs. To the best of our knowledge, SPP-Transformer is the first application of an end-to-end transformer in DJSSP, which not only improves the productivity of industrial scheduling but also provides a paradigm for future research on deep learning in DJSSP. © 2022 by the authors.},
	author_keywords = {deep learning; dynamic job shop scheduling problem; generalization; smart manufacturing; spatial pyramid pooling; transformer},
	correspondence_address = {H. Guo; School of Intelligent Systems Science and Engineering, Jinan University, Zhuhai, 519070, China; email: ghf-2005@163.com},
	publisher = {MDPI},
	issn = {20751702},
	language = {English},
	abbrev_source_title = {Mach.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Spanos2022,
	author = {Spanos, Athanasios C. and Gayialis, Sotiris P. and Kechagias, Evripidis P. and Papadopoulos, Georgios A.},
	title = {An Application of a Decision Support System Enabled by a Hybrid Algorithmic Framework for Production Scheduling in an SME Manufacturer},
	year = {2022},
	journal = {Algorithms},
	volume = {15},
	number = {10},
	doi = {10.3390/a15100372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140581115&doi=10.3390%2fa15100372&partnerID=40&md5=bc7022603f84aaf60594f281bf2c1573},
	affiliations = {Pricewaterhouse Coopers Business Solutions S.A., Chalandri, 15232, Greece; Sector of Industrial Management and Operational Research, School of Mechanical Engineering, National Technical University of Athens, Athens, 15772, Greece},
	abstract = {In this research, we present a hybrid algorithmic framework and its integration into the precise production scheduling system of a Greek metal forming factory. The system was created as a decision support tool to assist production planners in arranging weekly production orders to work centers and other manufacturing cells. The functionality offered includes dispatching priority rules, bottleneck identification for capacity planning, production order reallocation to alternate work centers and planning periods, interchangeable scheduling scenarios, and work-in-process availability checks based on bill of materials (BOM) precedence constraints. As a consequence, a solid short-term production plan is created, capable of absorbing shop floor risks such as machine failures and urgent orders. The primary design ideas are simplicity, ease of use, a flexible Gantt-chart-based graphical user interface (GUI), controllable report creation, and a modest development budget. The practical application takes place in a make-to-stock (MTS) environment with a complicated multi-level production process, defined due dates, and parallel machines. A critical component is the integration with legacy applications and the existing enterprise resource planning (ERP) system. The method adopted here avoids both overburdening the existing information system architecture with software pipeline spaghetti, as is common with point-to-point integration, and overshooting implementation costs, as is often the case with service-oriented architectures. © 2022 by the authors.},
	author_keywords = {decision support; dynamic job shops; hybrid metaheuristics; practical application; production scheduling; scheduling algorithms},
	keywords = {Artificial intelligence; Budget control; Decision support systems; Enterprise resource management; Enterprise resource planning; Graphical user interfaces; Information services; Integration; Planning; Production control; Scheduling; Service oriented architecture (SOA); Algorithmic framework; Decision supports; Dynamic job shop; Hybrid metaheuristics; Job-shop; Practical application; Production order; Production Scheduling; Production scheduling system; Support tool; Scheduling algorithms},
	correspondence_address = {S.P. Gayialis; Sector of Industrial Management and Operational Research, School of Mechanical Engineering, National Technical University of Athens, Athens, 15772, Greece; email: sotga@central.ntua.gr},
	publisher = {MDPI},
	issn = {19994893},
	language = {English},
	abbrev_source_title = {Algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Huang2023,
	author = {Huang, Jiang-Ping and Gao, Liang and Li, Xin-Yu and Zhang, Chun-Jiang},
	title = {A cooperative hierarchical deep reinforcement learning based multi-agent method for distributed job shop scheduling problem with random job arrivals},
	year = {2023},
	journal = {Computers and Industrial Engineering},
	volume = {185},
	doi = {10.1016/j.cie.2023.109650},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173274746&doi=10.1016%2fj.cie.2023.109650&partnerID=40&md5=9ac514534df06491e72b0ca801540be3},
	affiliations = {State Key Lab of Digital Manufacturing Equipment & Technology, Huazhong University of Science & Technology, Wuhan, 430074, China},
	abstract = {Distributed manufacturing can reduce the production cost through the cooperation among factories, and it has been an important trend in the industrial field. For the enterprises with daily delivered production tasks, the random job arrivals are regular. Thus, the Distributed Job-shop Scheduling Problem (DJSP) with random job arrivals is studied, and it is a typical case from the equipment manufacturing industry. The DJSP involves two coupled decision-making processes, job assigning and job sequencing, and the distributed and uncertain production environment requires the scheduling method to be more responsive and adaptive. Thus, a Deep Reinforcement Learning (DRL) based multi-agent method is explored, and it is composed of the assigning agent and the sequencing agent. Two Markov Decision Processes (MDPs) are formulated for the two agents respectively. In the MDP for the assigning agent, fourteen factory-and-job related features are extracted as the state features, seven composite assigning rules are designed as the candidate actions, and the reward depends on the total processing time of different factories. In the MDP of the sequencing agent, five machine-and-job related features are set as the state features, six sequencing rules make up the action space, and the change of the factory makespan is the reward. Besides, to enhance the learning ability of the agents, a Deep Q-Network (DQN) framework with variable threshold probability in the training stage is designed, which can balance the exploitation and exploration in the model training. The proposed multi-agent method's effectiveness is proved by the independent utility test and the comparison test that are based on 1350 production instances, and its practical value in the actual production is implied by the case study from an automotive engine manufacturing company. © 2023 Elsevier Ltd},
	author_keywords = {Deep reinforcement learning; Distributed manufacturing; Multi-agent; Shop scheduling},
	keywords = {Behavioral research; Costs; Decision making; Deep learning; Job shop scheduling; Learning algorithms; Learning systems; Markov processes; Multi agent systems; Deep reinforcement learning; Distributed job; Distributed manufacturing; Job shop scheduling problems; Markov Decision Processes; Multi agent; Production cost; Reinforcement learnings; Shop scheduling; State feature; Reinforcement learning},
	correspondence_address = {X.-Y. Li; State Key Lab of Digital Manufacturing Equipment & Technology, Huazhong University of Science & Technology, Wuhan, 430074, China; email: lixinyu@mail.hust.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {03608352},
	coden = {CINDD},
	language = {English},
	abbrev_source_title = {Comput Ind Eng},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Wang2023,
	author = {Wang, Zhenyu and Cai, Bin and Li, Jun and Yang, Deheng and Zhao, Yang and Xie, Huan},
	title = {Solving non-permutation flow-shop scheduling problem via a novel deep reinforcement learning approach},
	year = {2023},
	journal = {Computers and Operations Research},
	volume = {151},
	doi = {10.1016/j.cor.2022.106095},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143529925&doi=10.1016%2fj.cor.2022.106095&partnerID=40&md5=785e9a9194eece210e5bbb7efca56ee4},
	affiliations = {School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China; National University of Defense Technology, Hunan, 410073, China},
	abstract = {The non-permutation flow-shop scheduling problem (NPFS) is studied. We model it as a Markov decision process, creating a massive arena for reinforcement learning (RL) algorithms to work. While RL approaches with function approximation generate a significant number of sequences of highly linked states, few studies have examined the connection between the state sequences but merely shuffled their orders. To this end, this paper proposes a novel deep reinforcement learning algorithm, named LSTM-TD(0), to address NPFS. Specifically, we design fifteen state features to represent a production state at each scheduling point and fourteen actions to choose an unprocessed operation on a given machine. This study applies long short-term memory (LSTM) network to capture the intrinsic connection of the state sequences in RL-based scheduling approaches. Moreover, we enhance the LSTM model with the one-step temporal difference (TD(0)) algorithm to select each action impartially in relation to the state value, avoiding the frequent overestimation of action values in Q-learning. The proposed LSTM-TD(0) was trained using two LSTM networks and enhanced by redesigning the reward value. A series of comparative experiments were conducted between simple heuristic rules, metaheuristic rules, general DRL methods, and LSTM-TD(0) using a group of well-known benchmark problems with different scales. Comparative results have confirmed both the superiority and universality of LSTM-TD(0) over its competitors. Scalability tests reveal that our approach can generalize to instances of different sizes without retraining or knowledge transferring. © 2022 Elsevier Ltd},
	author_keywords = {Deep reinforcement learning; Long short-term memory; Non-permutation flow-shop scheduling problem; Temporal difference},
	keywords = {Brain; Heuristic methods; Learning algorithms; Long short-term memory; Machine shop practice; Markov processes; Deep reinforcement learning; Flow shop scheduling problem; Memory network; Non-permutation flow-shop scheduling problem; Permutation flow-shop scheduling; Reinforcement learning algorithms; Reinforcement learning approach; Reinforcement learnings; State sequences; Temporal differences; Reinforcement learning},
	correspondence_address = {B. Cai; School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China; email: caibin@cqu.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {03050548},
	coden = {CMORA},
	language = {English},
	abbrev_source_title = {Comp. Oper. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}